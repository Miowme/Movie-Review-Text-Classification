{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.utils import simple_preprocess\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "from sklearn import metrics\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "\n",
    "# If we have a GPU available, we'll set our device to GPU. We'll use this device variable later in our code.\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label\n",
      "0    2582\n",
      "1    2419\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i grew up (b. ) watching and loving the thunde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i put this movie in my dvd player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though i have great interest in biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im a die hard dads army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  i grew up (b. ) watching and loving the thunde...      0\n",
       "1  when i put this movie in my dvd player, and sa...      0\n",
       "2  why do people who do not know what a particula...      0\n",
       "3  even though i have great interest in biblical ...      0\n",
       "4  im a die hard dads army fan and nothing will e...      1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/movie.csv')\n",
    "df = df.loc[:5000]\n",
    "df['text'] = df['text'].str.lower()\n",
    "df['text'] = df['text'].str.strip()\n",
    "df['text'] = df['text'].apply(lambda x: re.sub('\\d+','',x))\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5001/5001 [00:01<00:00, 3704.80it/s]\n",
      "100%|██████████| 5001/5001 [00:02<00:00, 2013.85it/s]\n"
     ]
    }
   ],
   "source": [
    "df['tokens_gensim'] = df['text'].progress_apply(simple_preprocess)\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "a = list(stop_words)\n",
    "a.append('br')\n",
    "a.append('movie')\n",
    "a.append('watch')\n",
    "df['tokens_gensim'] = df['tokens_gensim'].progress_apply(lambda x: [i for i in x if i not in a])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokens_gensim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i grew up (b. ) watching and loving the thunde...</td>\n",
       "      <td>0</td>\n",
       "      <td>[grew, watching, loving, thunderbirds, mates, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>when i put this movie in my dvd player, and sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[put, dvd, player, sat, coke, chips, expectati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "      <td>[people, know, particular, time, past, like, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>even though i have great interest in biblical ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[even, though, great, interest, biblical, movi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>im a die hard dads army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "      <td>[im, die, hard, dads, army, fan, nothing, ever...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  i grew up (b. ) watching and loving the thunde...      0   \n",
       "1  when i put this movie in my dvd player, and sa...      0   \n",
       "2  why do people who do not know what a particula...      0   \n",
       "3  even though i have great interest in biblical ...      0   \n",
       "4  im a die hard dads army fan and nothing will e...      1   \n",
       "\n",
       "                                       tokens_gensim  \n",
       "0  [grew, watching, loving, thunderbirds, mates, ...  \n",
       "1  [put, dvd, player, sat, coke, chips, expectati...  \n",
       "2  [people, know, particular, time, past, like, f...  \n",
       "3  [even, though, great, interest, biblical, movi...  \n",
       "4  [im, die, hard, dads, army, fan, nothing, ever...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5001, 3)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3001, 3)\n",
      "(1000, 3)\n",
      "(1000, 3)\n"
     ]
    }
   ],
   "source": [
    "class_0 = df.loc[df.label == 0, :]\n",
    "class_1 = df.loc[df.label == 1, :]\n",
    "\n",
    "test_0 = class_0.iloc[:500, :]\n",
    "test_1 = class_1.iloc[:500, :]\n",
    "valid_0 = class_0.iloc[500:1000, :]\n",
    "valid_1 = class_1.iloc[500:1000, :]\n",
    "train_0 = class_0.iloc[1000:, :]\n",
    "train_1 = class_1.iloc[1000:, :]\n",
    "\n",
    "train_df = pd.concat([train_0, train_1], axis=0).reset_index(drop=True)\n",
    "print(train_df.shape)\n",
    "\n",
    "val_df = pd.concat([valid_0, valid_1], axis=0).reset_index(drop=True)\n",
    "print(val_df.shape)\n",
    "\n",
    "test_df = pd.concat([test_0, test_1], axis=0).reset_index(drop=True)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(glove_file, embedding_dim):\n",
    "    # Step 1: Read GloVe file and create word to index mapping and embedding matrix\n",
    "    word_to_idx = {}\n",
    "    embeddings = []\n",
    "\n",
    "    with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "        for idx, line in enumerate(f):\n",
    "            # Split line into word and embedding vector\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            \n",
    "            # Add word to vocab and corresponding embedding\n",
    "            word_to_idx[word] = idx\n",
    "            embeddings.append(vector)\n",
    "\n",
    "    # Step 2: Convert list of embeddings to a numpy array\n",
    "    embedding_matrix = np.stack(embeddings)\n",
    "\n",
    "    # Step 3: Create a PyTorch Embedding layer\n",
    "    # embedding_layer = nn.Embedding.from_pretrained(torch.tensor(embedding_matrix), freeze=True)\n",
    "    \n",
    "    return embedding_matrix, word_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GloveModel(nn.Module):\n",
    "    def __init__(self, embed_dim, hidden_dim, output_dim, num_layers):\n",
    "        super(GloveModel, self).__init__()\n",
    "        self.glove_weights,self.weight_idx = load_glove_embeddings(f'./pre-trained/glove.6B.{embed_dim}d.txt',embed_dim)\n",
    "        self.embedding = nn.Embedding.from_pretrained(torch.Tensor(self.glove_weights),freeze=True)\n",
    "        self.rnn = nn.GRU(embed_dim, hidden_dim, bidirectional=True, batch_first=True, dropout=0.2,num_layers=num_layers)\n",
    "        self.linear1 = nn.Linear(hidden_dim*2, output_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.sig = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size = x.size(0)\n",
    "        x = self.embedding(x)\n",
    "        output, x = self.rnn(x)\n",
    "        # x = self.dropout(x.squeeze(0))\n",
    "        out = self.linear1(output[:,-1,:])\n",
    "        return self.sig(out)\n",
    "    \n",
    "    def get_embeddings(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "    def get_weight_idx(self):\n",
    "        return self.weight_idx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GloveModel(100,32,1,3)\n",
    "word_to_idx = model.get_weight_idx()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sigarms', 399990),\n",
       " ('katuna', 399991),\n",
       " ('aqm', 399992),\n",
       " ('1.3775', 399993),\n",
       " ('corythosaurus', 399994),\n",
       " ('chanty', 399995),\n",
       " ('kronik', 399996),\n",
       " ('rolonda', 399997),\n",
       " ('zsombor', 399998),\n",
       " ('sandberger', 399999)]"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(word_to_idx.items())[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tensor(text_tokens):\n",
    "    new_tensor = []\n",
    "\n",
    "    for word in text_tokens:\n",
    "        if word in word_to_idx:\n",
    "            new_tensor.append(word_to_idx[word])\n",
    "        else:\n",
    "            new_tensor.append(0)\n",
    "    return np.array(new_tensor).astype('int')\n",
    "\n",
    "def padding_(sentences, seq_len):\n",
    "    features = np.zeros((len(sentences), seq_len),dtype=int)\n",
    "    for ii, review in enumerate(sentences):\n",
    "        if len(review) != 0:\n",
    "            features[ii, -len(review):] = np.array(review)[:seq_len]\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(train_df['tokens_gensim'].apply(generate_tensor))\n",
    "x_val = np.array(val_df['tokens_gensim'].apply(generate_tensor))\n",
    "x_test = np.array(test_df['tokens_gensim'].apply(generate_tensor))\n",
    "\n",
    "y_train = np.array(train_df['label']).astype('float32')\n",
    "y_val = np.array(val_df['label']).astype('float32')\n",
    "y_test = np.array(test_df['label']).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "608\n",
      "584\n",
      "546\n"
     ]
    }
   ],
   "source": [
    "print(np.max([len(i) for i in x_train]))\n",
    "print(np.max([len(i) for i in x_val]))\n",
    "print(np.max([len(i) for i in x_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = padding_(x_train,650)\n",
    "x_val = padding_(x_val,650)\n",
    "x_test = padding_(x_test,650)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3001, 650), (1000, 650), (1000, 650))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(torch.from_numpy(x_train), torch.from_numpy(y_train))\n",
    "val_data = TensorDataset(torch.from_numpy(x_val), torch.from_numpy(y_val))\n",
    "test_data = TensorDataset(torch.from_numpy(x_test), torch.from_numpy(y_test))\n",
    "\n",
    "dataset_sizes = {}\n",
    "dataset_sizes['train'] = len(train_data)\n",
    "dataset_sizes['val'] = len(val_data)\n",
    "dataset_sizes['test'] = len(test_data)\n",
    "\n",
    "# dataloaders\n",
    "batch_size = 32\n",
    "\n",
    "# make sure to SHUFFLE your data\n",
    "dataloaders = {}\n",
    "dataloaders[\"train\"] = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "dataloaders[\"val\"] = DataLoader(val_data, batch_size=batch_size)\n",
    "dataloaders[\"test\"] = DataLoader(test_data, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 39.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6404 Acc: 0.6285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 122.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.6415 Acc: 0.6510\n",
      "Epoch 2/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5119 Acc: 0.7434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 99.03it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5190 Acc: 0.7400\n",
      "Epoch 3/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.4330 Acc: 0.7994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 122.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5151 Acc: 0.7650\n",
      "Epoch 4/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3925 Acc: 0.8251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 104.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4849 Acc: 0.7600\n",
      "Epoch 5/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3546 Acc: 0.8487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 123.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5650 Acc: 0.7550\n",
      "Epoch 6/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3183 Acc: 0.8660\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 123.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4667 Acc: 0.7860\n",
      "Epoch 7/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2848 Acc: 0.8837\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 100.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4552 Acc: 0.7970\n",
      "Epoch 8/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2628 Acc: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 122.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.4754 Acc: 0.8020\n",
      "Epoch 9/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2228 Acc: 0.9130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 107.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5142 Acc: 0.8030\n",
      "Epoch 10/10\n",
      "--------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:02<00:00, 43.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2085 Acc: 0.9207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:00<00:00, 123.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.5342 Acc: 0.7990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lr=1e-3\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-2)\n",
    "\n",
    "epochs = 10 \n",
    "best_loss = np.inf\n",
    "best_acc = 0.0\n",
    "history_dict = {'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.to(device)\n",
    "    print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "    print('-' * 20)\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()\n",
    "\n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for inputs, labels in tqdm(dataloaders[phase]):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward\n",
    "            # track history if only in train\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                outputs = outputs.reshape(labels.shape)\n",
    "                preds = torch.round(outputs)\n",
    "                \n",
    "                loss = criterion(outputs, labels)\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # statistics\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_corrects += torch.sum(preds == labels)\n",
    "            \n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "        if phase == 'train':\n",
    "            history_dict['train_loss'].append(epoch_loss)\n",
    "            history_dict['train_acc'].append(epoch_acc.cpu().numpy())\n",
    "        elif phase == 'val':\n",
    "            history_dict['val_loss'].append(epoch_loss)\n",
    "            history_dict['val_acc'].append(epoch_acc.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 212.83it/s]\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "test_loss = []\n",
    "y_pred, y_true, = [], []\n",
    "y_prob = []\n",
    "count = 0\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, classes in tqdm(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        labels = classes.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        outputs = outputs.reshape(labels.shape)\n",
    "        preds = torch.round(outputs)\n",
    "        test_loss.append(criterion(outputs, labels).cpu().numpy())\n",
    "\n",
    "        count+=1\n",
    "        # print(\"Processed {} images, current loss = {}\".format(count,np.mean(test_loss)))\n",
    "        y_pred.append(preds.cpu()[0].tolist())\n",
    "        y_true.append(labels.cpu()[0].tolist())\n",
    "        y_prob.append(outputs.cpu()[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[378, 122],\n",
       "       [ 71, 429]], dtype=int64)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_true=y_true,y_pred=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.76      0.80       500\n",
      "         1.0       0.78      0.86      0.82       500\n",
      "\n",
      "    accuracy                           0.81      1000\n",
      "   macro avg       0.81      0.81      0.81      1000\n",
      "weighted avg       0.81      0.81      0.81      1000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_true,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_prob)\n",
    "plt.plot(\n",
    "    fpr,\n",
    "    tpr,\n",
    "    label=\"ROC curve (area = {0:0.2f})\".format(metrics.roc_auc_score(y_test,y_prob)),\n",
    "    color=\"navy\",\n",
    "#     linestyle=\":\",\n",
    "    linewidth=4,\n",
    ")\n",
    "\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend(loc=\"lower right\",prop={'size': 6})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = 'exp/07'\n",
    "os.makedirs(exp_path,exist_ok=True)\n",
    "torch.save(model.state_dict(),os.path.join(exp_path,\"best_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = GloveModel(100,32,1,3)\n",
    "ckpt = torch.load(os.path.join(exp_path,\"best_model.pth\"))\n",
    "model.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('embedding.weight',\n",
       "              tensor([[-0.0382, -0.2449,  0.7281,  ..., -0.1459,  0.8278,  0.2706],\n",
       "                      [-0.1077,  0.1105,  0.5981,  ..., -0.8316,  0.4529,  0.0826],\n",
       "                      [-0.3398,  0.2094,  0.4635,  ..., -0.2339,  0.4730, -0.0288],\n",
       "                      ...,\n",
       "                      [ 0.3609, -0.1692, -0.3270,  ...,  0.2714, -0.2919,  0.1611],\n",
       "                      [-0.1046, -0.5047, -0.4933,  ...,  0.4253, -0.5125, -0.1705],\n",
       "                      [ 0.2837, -0.6263, -0.4435,  ...,  0.4368, -0.8261, -0.1570]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l0',\n",
       "              tensor([[ 0.2219,  0.1005,  0.2506,  ..., -0.0782, -0.2742, -0.1927],\n",
       "                      [ 0.0961,  0.1083,  0.1230,  ..., -0.1068, -0.0272, -0.0152],\n",
       "                      [-0.0746, -0.0253, -0.1701,  ...,  0.1163,  0.1143,  0.0714],\n",
       "                      ...,\n",
       "                      [-0.0247,  0.1625,  0.0260,  ...,  0.1776, -0.0916, -0.0596],\n",
       "                      [-0.0867,  0.1983, -0.0560,  ..., -0.0168,  0.1211,  0.0416],\n",
       "                      [-0.0828, -0.0907, -0.0035,  ..., -0.0327, -0.1235, -0.0074]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0',\n",
       "              tensor([[-0.2724,  0.0228,  0.0536,  ..., -0.0292, -0.1822,  0.0204],\n",
       "                      [ 0.0265, -0.1186,  0.2352,  ..., -0.1542,  0.1627, -0.0752],\n",
       "                      [-0.0512,  0.1028,  0.1017,  ...,  0.0319,  0.0962, -0.0184],\n",
       "                      ...,\n",
       "                      [-0.0081, -0.0892,  0.0197,  ..., -0.0985, -0.1802,  0.1479],\n",
       "                      [-0.0064, -0.1984,  0.1694,  ...,  0.1788, -0.0225,  0.1571],\n",
       "                      [ 0.0885, -0.0993, -0.0246,  ...,  0.1092, -0.0614, -0.1032]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0',\n",
       "              tensor([-0.0414, -0.0330,  0.0712,  0.1130, -0.0961, -0.1616, -0.0496,  0.1994,\n",
       "                       0.1043,  0.0516, -0.0294, -0.0180, -0.1479,  0.0774,  0.0775, -0.0539,\n",
       "                       0.1217,  0.0485,  0.1212,  0.1924, -0.0586, -0.0682,  0.1895, -0.0216,\n",
       "                      -0.1096,  0.0161, -0.0605, -0.1905, -0.0101, -0.1340,  0.0242, -0.0442,\n",
       "                      -0.0264,  0.1341,  0.2652,  0.0058,  0.1840,  0.3681,  0.2889, -0.0242,\n",
       "                      -0.1325, -0.0553, -0.0170,  0.0405,  0.1391,  0.2572,  0.1374, -0.0987,\n",
       "                      -0.0475, -0.0174,  0.0875, -0.0623,  0.4303,  0.0424, -0.0651,  0.0199,\n",
       "                       0.2591,  0.1643,  0.3403,  0.0058,  0.0565,  0.0340,  0.0616,  0.0894,\n",
       "                      -0.1332,  0.0370,  0.0075, -0.0121, -0.0520, -0.0981, -0.1436, -0.1072,\n",
       "                      -0.1028,  0.0803, -0.1286, -0.1220,  0.1046,  0.1448,  0.0864, -0.0445,\n",
       "                      -0.0575,  0.0308, -0.1127, -0.1333,  0.0778, -0.0065, -0.0730,  0.0337,\n",
       "                      -0.1273,  0.0756,  0.0724, -0.0479,  0.0294, -0.1591,  0.1140,  0.0609],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0',\n",
       "              tensor([ 0.0573,  0.1637, -0.0534, -0.1097, -0.0600,  0.1082, -0.0742,  0.2812,\n",
       "                       0.0983, -0.0078,  0.0111,  0.1867, -0.0519, -0.1705, -0.0839, -0.0184,\n",
       "                      -0.1143,  0.0247, -0.0970,  0.1167, -0.0348,  0.0571,  0.1328,  0.1068,\n",
       "                       0.0220,  0.0387, -0.1518,  0.0667, -0.0390, -0.1707,  0.1714,  0.1141,\n",
       "                      -0.1010,  0.0469,  0.1248, -0.0952, -0.0165,  0.2488,  0.3519, -0.0273,\n",
       "                      -0.0848,  0.1420,  0.0978,  0.1000, -0.0167,  0.0373,  0.0968,  0.1561,\n",
       "                       0.0049, -0.1062, -0.0635,  0.0219,  0.3926, -0.0783, -0.1576,  0.1480,\n",
       "                      -0.0529,  0.1600,  0.2009, -0.1176,  0.0603,  0.0142,  0.2664,  0.3151,\n",
       "                      -0.0993, -0.0109,  0.0172, -0.0451, -0.0274, -0.0064, -0.1152,  0.0347,\n",
       "                      -0.0646, -0.0687,  0.0574,  0.0963, -0.0420, -0.0155,  0.0376,  0.0944,\n",
       "                      -0.0383, -0.1798,  0.1003, -0.1504,  0.0340, -0.0673, -0.0820,  0.0124,\n",
       "                      -0.0441,  0.0623, -0.1376, -0.0074,  0.0363, -0.0022,  0.0797,  0.0549],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l0_reverse',\n",
       "              tensor([[-0.0522,  0.1345, -0.0486,  ...,  0.0823, -0.0063, -0.0142],\n",
       "                      [-0.1316,  0.1011, -0.0356,  ...,  0.1640, -0.0098, -0.0306],\n",
       "                      [-0.0820, -0.1575, -0.0799,  ..., -0.1609, -0.1611,  0.0824],\n",
       "                      ...,\n",
       "                      [-0.1577,  0.1488,  0.0762,  ...,  0.0311,  0.0590, -0.2211],\n",
       "                      [-0.0308, -0.1071, -0.1041,  ...,  0.1012, -0.0278,  0.1643],\n",
       "                      [ 0.0090,  0.1963,  0.0311,  ...,  0.0912,  0.0207, -0.0254]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l0_reverse',\n",
       "              tensor([[ 0.1624,  0.2487, -0.2388,  ...,  0.1987,  0.0024, -0.2225],\n",
       "                      [-0.2543, -0.1595, -0.0869,  ...,  0.3375,  0.2789,  0.2010],\n",
       "                      [-0.0085,  0.0885,  0.0558,  ..., -0.0108,  0.1994,  0.1606],\n",
       "                      ...,\n",
       "                      [ 0.1046,  0.0124, -0.1418,  ...,  0.1535,  0.1008,  0.0462],\n",
       "                      [-0.1648,  0.0783, -0.1002,  ...,  0.1131,  0.1007, -0.1258],\n",
       "                      [ 0.1036, -0.1325,  0.2118,  ..., -0.0899,  0.0801, -0.0713]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l0_reverse',\n",
       "              tensor([ 0.0241,  0.0683,  0.0394, -0.0826, -0.0581,  0.2064, -0.0740,  0.0105,\n",
       "                      -0.0189, -0.1299, -0.0787,  0.0796,  0.1032,  0.1417,  0.1270, -0.0409,\n",
       "                       0.0404, -0.0111,  0.1716,  0.0389, -0.0554,  0.0620,  0.0312,  0.1512,\n",
       "                       0.0641,  0.1227,  0.1252,  0.0365, -0.1014,  0.1413, -0.1336, -0.0669,\n",
       "                      -0.1463,  0.0423, -0.0726,  0.0474,  0.0817,  0.1623, -0.1296, -0.1323,\n",
       "                      -0.1113,  0.0456, -0.1926,  0.1726,  0.1067, -0.2206,  0.0009, -0.0693,\n",
       "                       0.1039,  0.1542, -0.1894, -0.0132, -0.0213, -0.0403,  0.0965,  0.1464,\n",
       "                       0.0658, -0.0147,  0.0379,  0.0117,  0.0709,  0.2394,  0.1384, -0.2521,\n",
       "                      -0.1285, -0.0423,  0.0744, -0.0885,  0.0599,  0.0280,  0.0166, -0.0893,\n",
       "                       0.1465,  0.0414, -0.0807, -0.0013,  0.1033,  0.1189, -0.1113,  0.0136,\n",
       "                       0.1060, -0.0415,  0.0644,  0.0099,  0.0353, -0.0912, -0.1810,  0.1421,\n",
       "                       0.0702,  0.1317, -0.1104, -0.1737,  0.1251, -0.0453, -0.1365, -0.1282],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l0_reverse',\n",
       "              tensor([ 0.0323, -0.0502, -0.0275, -0.0597,  0.1229,  0.1868, -0.0553,  0.0561,\n",
       "                       0.0403, -0.0614,  0.1499,  0.0616,  0.1112,  0.0029, -0.1174, -0.0055,\n",
       "                       0.0894,  0.1400,  0.0686,  0.0628, -0.1549,  0.0380,  0.0503, -0.1412,\n",
       "                       0.0553,  0.0300, -0.1679, -0.0264,  0.0924,  0.0787, -0.0019,  0.0720,\n",
       "                       0.0011,  0.2799, -0.1179,  0.2690,  0.0731,  0.0865, -0.0157,  0.1363,\n",
       "                      -0.0477, -0.1039,  0.1069,  0.0209,  0.0807,  0.0953,  0.0347, -0.0728,\n",
       "                       0.0046,  0.2173,  0.0248,  0.1361, -0.0106,  0.0240, -0.1490, -0.1163,\n",
       "                       0.3127,  0.1331, -0.0543,  0.1795,  0.1090, -0.0041,  0.0781,  0.0813,\n",
       "                      -0.0160, -0.1548,  0.0863, -0.1442, -0.0244,  0.0503, -0.1627, -0.1268,\n",
       "                       0.0897,  0.2113,  0.1675,  0.1111, -0.0449,  0.0509,  0.1262, -0.0072,\n",
       "                      -0.1535, -0.0332, -0.0887, -0.1782,  0.1677,  0.0055,  0.0475,  0.0598,\n",
       "                      -0.0038, -0.1690,  0.0158, -0.1296, -0.0094, -0.0633, -0.1150,  0.1564],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l1',\n",
       "              tensor([[ 0.1837, -0.1321, -0.1489,  ..., -0.0811, -0.0157,  0.0456],\n",
       "                      [ 0.1356,  0.0419, -0.2082,  ..., -0.1110, -0.1840, -0.0457],\n",
       "                      [-0.1487,  0.0450,  0.1001,  ..., -0.2615,  0.0635, -0.2391],\n",
       "                      ...,\n",
       "                      [-0.0858, -0.1536,  0.0158,  ...,  0.1521, -0.1459, -0.2049],\n",
       "                      [ 0.0714, -0.2144, -0.1058,  ..., -0.0158, -0.0845, -0.2173],\n",
       "                      [ 0.1334, -0.0857,  0.2214,  ..., -0.0146,  0.1569,  0.1639]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l1',\n",
       "              tensor([[ 0.0776,  0.1412, -0.0768,  ...,  0.0268,  0.0754,  0.0345],\n",
       "                      [ 0.1125, -0.1190, -0.0147,  ..., -0.1558,  0.1626,  0.0671],\n",
       "                      [-0.0455, -0.1220,  0.2463,  ...,  0.0350,  0.1395,  0.0655],\n",
       "                      ...,\n",
       "                      [ 0.0082,  0.0473, -0.0801,  ...,  0.1951,  0.0667,  0.1075],\n",
       "                      [ 0.1631,  0.0832,  0.1212,  ..., -0.0128,  0.0461,  0.0208],\n",
       "                      [-0.1011, -0.1278,  0.1285,  ...,  0.1099, -0.1512,  0.1865]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l1',\n",
       "              tensor([ 0.2162,  0.1680, -0.1142, -0.0497,  0.1357,  0.0788,  0.0929, -0.1348,\n",
       "                      -0.1918,  0.0722, -0.0526,  0.0866,  0.0610,  0.1438, -0.0494,  0.1547,\n",
       "                      -0.0179,  0.0785,  0.0312, -0.1443,  0.2027,  0.0267, -0.0148,  0.0766,\n",
       "                       0.1581, -0.0424,  0.0241, -0.0828, -0.0367,  0.0551,  0.2148, -0.0910,\n",
       "                       0.0570,  0.0655,  0.0497,  0.0327,  0.2229, -0.1675,  0.0950,  0.2594,\n",
       "                      -0.1767,  0.0915, -0.1420,  0.1235, -0.1393,  0.3167, -0.0121, -0.0351,\n",
       "                       0.2163, -0.0246,  0.3621,  0.0580,  0.0248,  0.0857, -0.0275,  0.1957,\n",
       "                       0.0691,  0.0942,  0.0661,  0.0503,  0.0670,  0.2842, -0.1533,  0.0079,\n",
       "                       0.1754,  0.0771,  0.1057,  0.1504, -0.0153, -0.0305, -0.1641, -0.1079,\n",
       "                       0.1397,  0.0422, -0.1897, -0.0627, -0.1070, -0.0061, -0.0068, -0.0135,\n",
       "                       0.1837,  0.1153,  0.0513,  0.0990, -0.0316, -0.1234,  0.1204, -0.0228,\n",
       "                       0.0940,  0.0269,  0.1898,  0.0876,  0.0900,  0.0288,  0.0164, -0.1018],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l1',\n",
       "              tensor([ 0.0061,  0.0450,  0.2056,  0.0703, -0.0786, -0.0775, -0.1400,  0.0858,\n",
       "                      -0.1302,  0.0061,  0.0989,  0.1571,  0.2518,  0.0835,  0.0905, -0.1084,\n",
       "                       0.0300, -0.1436,  0.1214,  0.1252,  0.2030, -0.1545, -0.0165,  0.2119,\n",
       "                      -0.0640, -0.0878,  0.1830, -0.0433,  0.0984, -0.1015, -0.0878, -0.0641,\n",
       "                      -0.1462,  0.0133,  0.0541, -0.0006,  0.3096, -0.0665, -0.1023,  0.2193,\n",
       "                      -0.0464, -0.1169, -0.1370,  0.0287,  0.0441,  0.0384,  0.1227, -0.0356,\n",
       "                       0.2577, -0.0696,  0.3192,  0.0122, -0.2229, -0.0470,  0.0324,  0.2621,\n",
       "                       0.1067,  0.1542, -0.0494, -0.0308,  0.3061,  0.0349,  0.0676, -0.1598,\n",
       "                       0.1166,  0.1680, -0.0296, -0.0768,  0.1586, -0.1336,  0.0076,  0.0297,\n",
       "                      -0.1364, -0.1715, -0.0259,  0.1455, -0.1622, -0.0440, -0.0073,  0.0579,\n",
       "                      -0.0720, -0.0422,  0.0831,  0.0740,  0.1014,  0.0955,  0.1141,  0.1619,\n",
       "                       0.0383,  0.0818, -0.0119,  0.0616, -0.1864,  0.0671, -0.1307,  0.0992],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l1_reverse',\n",
       "              tensor([[-0.1241, -0.1292, -0.0392,  ...,  0.2338, -0.0806,  0.0168],\n",
       "                      [ 0.0592,  0.1971, -0.1111,  ...,  0.1480,  0.0855, -0.1244],\n",
       "                      [-0.2308,  0.0409,  0.1656,  ..., -0.0187,  0.1632,  0.0194],\n",
       "                      ...,\n",
       "                      [ 0.1343, -0.1711, -0.0382,  ..., -0.1351, -0.1306,  0.0445],\n",
       "                      [ 0.0585,  0.0622, -0.1250,  ..., -0.1928, -0.0227, -0.0192],\n",
       "                      [-0.0394,  0.0942, -0.1499,  ..., -0.0691, -0.0296,  0.0762]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l1_reverse',\n",
       "              tensor([[-0.1256, -0.2056, -0.1756,  ...,  0.0509, -0.0461, -0.1754],\n",
       "                      [ 0.1098,  0.0734, -0.1229,  ..., -0.0195, -0.0728,  0.0453],\n",
       "                      [ 0.0593,  0.1266,  0.0284,  ...,  0.1599,  0.1184,  0.0651],\n",
       "                      ...,\n",
       "                      [ 0.1228, -0.1745,  0.0556,  ..., -0.1050,  0.1315, -0.0423],\n",
       "                      [-0.0660, -0.1286, -0.0490,  ...,  0.0737,  0.1546,  0.1344],\n",
       "                      [-0.0444,  0.0211,  0.2790,  ...,  0.1641, -0.1037,  0.1836]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l1_reverse',\n",
       "              tensor([ 1.1445e-02,  6.5021e-02, -1.0485e-01, -4.6101e-02,  2.9817e-02,\n",
       "                       9.4129e-02,  3.1817e-02,  1.4478e-01, -1.5391e-01,  1.2867e-01,\n",
       "                      -1.2827e-01,  7.0178e-02, -7.7802e-02,  5.1934e-02, -6.4512e-02,\n",
       "                       6.6067e-02,  1.5467e-01,  4.0842e-03, -1.8264e-02, -6.3758e-02,\n",
       "                       4.2872e-02,  1.0764e-01,  1.1570e-01, -3.8525e-02, -5.4677e-02,\n",
       "                       1.3326e-01,  6.0920e-02, -9.1778e-02, -4.1215e-02, -7.6180e-02,\n",
       "                      -1.9464e-01,  1.5733e-01,  4.4008e-02, -2.5141e-01,  1.6634e-01,\n",
       "                       1.3048e-01,  4.2858e-02, -8.3421e-02, -3.1544e-02,  7.0926e-05,\n",
       "                       1.1743e-01,  1.0801e-02,  1.0186e-01, -9.3716e-02, -9.1649e-03,\n",
       "                      -1.7939e-01, -1.5968e-01, -2.0039e-02, -7.9990e-02, -4.6802e-02,\n",
       "                      -1.6256e-01, -2.4037e-01, -1.2000e-01, -7.6389e-03, -1.9759e-01,\n",
       "                      -1.9373e-01,  2.7038e-02, -2.1073e-01, -1.3538e-01, -2.9134e-02,\n",
       "                       1.9834e-02, -1.0487e-01, -1.2258e-01, -1.3651e-01, -5.3253e-02,\n",
       "                      -1.1433e-01,  3.8924e-02,  5.0914e-02, -9.6192e-02,  9.2648e-02,\n",
       "                      -1.6381e-01,  1.0168e-01,  7.5794e-02, -1.5537e-01,  9.2859e-02,\n",
       "                       3.6376e-02,  5.0495e-02, -2.3159e-01, -1.2564e-01,  4.0021e-02,\n",
       "                      -1.1115e-01,  1.7434e-01,  1.4820e-01, -3.4284e-02, -3.8012e-02,\n",
       "                       1.3339e-01, -2.1174e-02,  8.0563e-02, -7.9872e-02, -1.3874e-01,\n",
       "                       3.7780e-02,  4.2645e-02,  1.7244e-01,  7.3894e-02,  2.0758e-01,\n",
       "                       7.7477e-02], device='cuda:0')),\n",
       "             ('rnn.bias_hh_l1_reverse',\n",
       "              tensor([ 1.5519e-01,  1.3623e-01,  9.4644e-02,  1.0493e-01,  2.2234e-01,\n",
       "                       1.2090e-01,  2.0968e-01, -6.2654e-02, -1.2161e-01,  1.4310e-01,\n",
       "                      -2.2984e-02,  1.4516e-02,  8.4743e-02, -9.1946e-02, -1.0171e-01,\n",
       "                       1.0517e-01,  1.8890e-01,  6.5175e-02,  7.6285e-02, -1.0881e-01,\n",
       "                       7.2497e-02,  1.1463e-01, -8.7091e-04,  1.4604e-01, -1.5400e-01,\n",
       "                       1.7693e-01,  5.4921e-02,  9.6128e-02, -4.0754e-02, -5.9536e-02,\n",
       "                      -3.7969e-02, -1.1058e-02, -8.6658e-02, -1.8590e-01,  3.3165e-02,\n",
       "                       9.3151e-02, -7.5081e-02, -2.9493e-01, -6.8799e-02, -2.8498e-02,\n",
       "                      -1.3923e-01,  6.7558e-02,  9.5371e-02, -7.9794e-02, -8.2451e-02,\n",
       "                       1.5602e-01, -1.2152e-01, -2.7173e-02, -1.9071e-01, -5.1356e-02,\n",
       "                       1.3886e-01, -9.9593e-02, -1.3424e-02, -1.1101e-01, -2.2585e-01,\n",
       "                      -2.2934e-01, -3.4451e-02, -7.1944e-02, -3.3430e-02, -1.3125e-01,\n",
       "                       9.8832e-02, -1.9886e-01, -1.0379e-01,  6.4842e-02, -1.2187e-01,\n",
       "                      -1.3120e-01,  5.8896e-02,  1.4259e-01, -2.1456e-01,  1.1097e-01,\n",
       "                      -2.1666e-01,  1.1804e-02, -1.0320e-01, -1.5802e-01,  1.7429e-01,\n",
       "                       1.2770e-01, -3.5333e-02, -1.6569e-01,  1.4928e-01,  9.0316e-02,\n",
       "                       1.0104e-04, -1.2584e-01, -6.3081e-03,  1.6538e-01,  1.3141e-01,\n",
       "                       1.5697e-01, -1.1692e-01,  1.1499e-01,  9.8631e-03,  7.3540e-02,\n",
       "                       1.1018e-01, -1.7910e-03,  5.9098e-02, -1.2644e-01, -1.1378e-01,\n",
       "                       2.5796e-02], device='cuda:0')),\n",
       "             ('rnn.weight_ih_l2',\n",
       "              tensor([[ 0.0062,  0.1363, -0.0639,  ...,  0.2061,  0.1621,  0.0032],\n",
       "                      [-0.0673,  0.1047,  0.0976,  ...,  0.0710, -0.0045,  0.0648],\n",
       "                      [-0.1430, -0.0840, -0.0323,  ...,  0.1339, -0.0341,  0.0735],\n",
       "                      ...,\n",
       "                      [-0.1818, -0.1584,  0.0864,  ..., -0.1723, -0.1259,  0.0161],\n",
       "                      [ 0.0212,  0.1250,  0.0268,  ..., -0.0073,  0.0261,  0.0660],\n",
       "                      [-0.0885,  0.0027,  0.0164,  ...,  0.0259,  0.1029, -0.0843]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l2',\n",
       "              tensor([[ 0.1087,  0.0680,  0.0510,  ..., -0.1084, -0.1049,  0.2147],\n",
       "                      [ 0.1542, -0.0954, -0.1254,  ...,  0.1175, -0.0846, -0.0119],\n",
       "                      [-0.2649, -0.2162,  0.0567,  ...,  0.1538, -0.0976,  0.0979],\n",
       "                      ...,\n",
       "                      [-0.2089,  0.0687, -0.1230,  ...,  0.0198, -0.0249, -0.1164],\n",
       "                      [-0.1664,  0.1103, -0.1067,  ..., -0.1092,  0.1280,  0.2612],\n",
       "                      [ 0.0945,  0.0159,  0.0875,  ...,  0.1860, -0.0760,  0.1705]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l2',\n",
       "              tensor([ 3.5580e-02,  1.6476e-01,  1.6853e-01, -1.4711e-01,  1.3403e-01,\n",
       "                      -8.5170e-03,  1.2169e-01, -5.4909e-02, -1.6948e-01,  4.7380e-02,\n",
       "                       6.6411e-02,  1.3059e-01, -7.7608e-05,  1.9689e-01, -2.2940e-01,\n",
       "                      -3.9457e-02,  1.3994e-01, -1.2339e-01,  5.0726e-02,  1.1029e-01,\n",
       "                      -1.3816e-01, -8.8218e-02, -6.1349e-02, -2.6516e-02,  6.0921e-02,\n",
       "                      -3.6259e-02,  2.3765e-02,  1.2654e-01,  9.1760e-02,  8.7851e-02,\n",
       "                      -6.0678e-02, -6.0860e-02,  1.6964e-01, -6.0752e-02, -8.6021e-02,\n",
       "                       7.7157e-03,  2.6766e-01,  2.8749e-01,  2.7024e-01, -2.1802e-01,\n",
       "                       4.3974e-02, -1.7040e-01,  2.0453e-01, -1.5443e-01,  1.2233e-01,\n",
       "                       8.4232e-02,  1.4349e-03,  3.5447e-02,  1.4458e-01,  2.4335e-02,\n",
       "                       1.3560e-01,  7.2427e-02,  3.1807e-01, -1.0686e-01, -6.9123e-02,\n",
       "                       1.3835e-01,  3.0581e-01,  3.1729e-01,  2.2930e-01,  8.4998e-02,\n",
       "                      -4.9597e-02,  1.8373e-01, -4.5494e-02,  1.9799e-01, -2.3262e-02,\n",
       "                      -1.0757e-01,  1.4370e-02, -3.0892e-02,  1.1292e-01, -6.2317e-02,\n",
       "                       1.0287e-01,  1.0877e-01, -7.4365e-02, -4.7330e-02,  3.3736e-02,\n",
       "                      -6.5383e-02,  1.8323e-01, -7.9835e-02,  3.6316e-03, -6.6972e-02,\n",
       "                       1.0405e-01, -2.8761e-02,  9.5185e-02, -1.1072e-01,  1.6742e-01,\n",
       "                      -8.2628e-02,  3.8287e-02,  3.1218e-02, -3.4987e-02, -4.6229e-02,\n",
       "                      -1.6853e-01,  6.2628e-02,  1.3973e-01, -2.0051e-02, -3.8728e-02,\n",
       "                       1.1749e-01], device='cuda:0')),\n",
       "             ('rnn.bias_hh_l2',\n",
       "              tensor([ 0.1886,  0.1035,  0.0293,  0.1923, -0.0297, -0.0076, -0.0535,  0.0657,\n",
       "                      -0.0265,  0.1585, -0.1196,  0.0496,  0.1819,  0.1197, -0.0308,  0.0827,\n",
       "                      -0.1418, -0.0267,  0.0695,  0.1764, -0.1473,  0.0963,  0.0327, -0.0148,\n",
       "                      -0.0752, -0.1381, -0.1462,  0.0393,  0.1219,  0.1724,  0.1795, -0.0851,\n",
       "                       0.0624, -0.1797,  0.1086,  0.0717,  0.1053,  0.0582,  0.2349, -0.1726,\n",
       "                       0.2221, -0.1280, -0.0042,  0.1020, -0.0139, -0.0431, -0.0340, -0.0838,\n",
       "                       0.0424, -0.1543, -0.0012, -0.0098,  0.2859,  0.1214, -0.0267,  0.2411,\n",
       "                       0.2431,  0.1255,  0.0461, -0.0598, -0.0225, -0.0347, -0.1575,  0.1502,\n",
       "                       0.1543,  0.1047,  0.1690,  0.0084,  0.1349,  0.1279,  0.0267, -0.0530,\n",
       "                       0.1215,  0.2048, -0.1371,  0.0380,  0.0562,  0.0107, -0.0123,  0.0707,\n",
       "                      -0.0058,  0.0610,  0.1304,  0.0908,  0.0825, -0.0656, -0.0336,  0.1116,\n",
       "                      -0.1606,  0.0881,  0.0174, -0.1474,  0.0080,  0.0473,  0.1584,  0.0964],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_ih_l2_reverse',\n",
       "              tensor([[-0.1187, -0.1889,  0.0838,  ...,  0.0520, -0.0922, -0.1084],\n",
       "                      [ 0.1466,  0.1420,  0.1097,  ...,  0.2059, -0.1258, -0.0813],\n",
       "                      [ 0.0310, -0.1928,  0.1342,  ...,  0.0043, -0.0884, -0.0089],\n",
       "                      ...,\n",
       "                      [ 0.0997,  0.1118, -0.1099,  ...,  0.0076, -0.1798, -0.0491],\n",
       "                      [ 0.1396,  0.1155,  0.0965,  ...,  0.0567, -0.0217,  0.0533],\n",
       "                      [-0.0433, -0.0768, -0.1186,  ..., -0.1972, -0.1518, -0.0581]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.weight_hh_l2_reverse',\n",
       "              tensor([[-0.1718,  0.0915,  0.0806,  ..., -0.0960,  0.1440,  0.0382],\n",
       "                      [-0.0203,  0.1056,  0.0309,  ...,  0.0394,  0.1361, -0.1585],\n",
       "                      [ 0.1016,  0.0311, -0.0589,  ..., -0.1496,  0.0665,  0.1481],\n",
       "                      ...,\n",
       "                      [ 0.0027, -0.1129,  0.0358,  ...,  0.0053,  0.1523, -0.0279],\n",
       "                      [ 0.1090,  0.1705, -0.0711,  ..., -0.1711, -0.1533,  0.0947],\n",
       "                      [-0.0774,  0.0918,  0.1229,  ...,  0.0795,  0.0255, -0.0331]],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_ih_l2_reverse',\n",
       "              tensor([ 0.0393, -0.1719,  0.0782,  0.0926,  0.0721,  0.0932,  0.1519, -0.1280,\n",
       "                      -0.0162,  0.0199, -0.1354, -0.0792,  0.1327, -0.1163, -0.0334,  0.1359,\n",
       "                      -0.0943,  0.1344, -0.0853,  0.0090,  0.0997, -0.0992, -0.1784, -0.0707,\n",
       "                       0.1156, -0.1427,  0.0802, -0.1649,  0.1160, -0.0777, -0.1440,  0.0493,\n",
       "                      -0.1807,  0.0131,  0.0873,  0.0355,  0.0481, -0.0132, -0.0831,  0.0009,\n",
       "                       0.0655, -0.2861, -0.1210, -0.0342, -0.1903, -0.1728, -0.0404, -0.0909,\n",
       "                      -0.1428, -0.0921, -0.0945, -0.2086,  0.0195, -0.2503, -0.0055, -0.0327,\n",
       "                      -0.0787,  0.0966, -0.0948, -0.0577, -0.1819, -0.2443, -0.2405, -0.1809,\n",
       "                      -0.1226, -0.1591,  0.1682,  0.0896, -0.1346, -0.0956, -0.0376, -0.0295,\n",
       "                       0.0674, -0.0744, -0.1208, -0.1762,  0.1145,  0.0859,  0.1336, -0.1014,\n",
       "                      -0.1068,  0.0040,  0.0439,  0.1766,  0.0275, -0.0509, -0.0883, -0.0574,\n",
       "                      -0.1300,  0.0210, -0.1805,  0.1602,  0.0571, -0.1059, -0.1813,  0.1513],\n",
       "                     device='cuda:0')),\n",
       "             ('rnn.bias_hh_l2_reverse',\n",
       "              tensor([ 0.0038,  0.1211,  0.1721,  0.0905, -0.0278,  0.1054, -0.0608, -0.0813,\n",
       "                       0.0475,  0.0653,  0.0111, -0.1441,  0.1540, -0.0723,  0.1387, -0.0771,\n",
       "                       0.1562,  0.0442,  0.0689, -0.1374, -0.0543, -0.1196,  0.1107,  0.1759,\n",
       "                      -0.1520, -0.1777, -0.0460, -0.0089, -0.1058,  0.0597, -0.0224, -0.1555,\n",
       "                      -0.2152,  0.1256, -0.1981,  0.0730,  0.0838,  0.0757, -0.0898, -0.1404,\n",
       "                      -0.0704, -0.0937, -0.0609,  0.1312, -0.1830, -0.0598, -0.0007, -0.2033,\n",
       "                      -0.1410, -0.2731, -0.0159, -0.2324, -0.1572, -0.1732,  0.0312,  0.1194,\n",
       "                      -0.0960, -0.1227, -0.2636,  0.0926, -0.0572, -0.0547, -0.2431, -0.1345,\n",
       "                       0.0198,  0.1607,  0.1709,  0.1601, -0.1012,  0.0169,  0.1175, -0.1242,\n",
       "                      -0.1367, -0.1344,  0.1135,  0.0374, -0.0898, -0.0282, -0.0211,  0.0303,\n",
       "                       0.0862, -0.0900, -0.1480, -0.0915, -0.1448,  0.1434, -0.1051,  0.1685,\n",
       "                       0.1647,  0.0048, -0.0477,  0.1537,  0.0269,  0.1085,  0.1620,  0.1617],\n",
       "                     device='cuda:0')),\n",
       "             ('linear1.weight',\n",
       "              tensor([[ 0.1738,  0.1934, -0.1566,  0.1878, -0.1335,  0.1905, -0.1733,  0.0423,\n",
       "                       -0.1927, -0.1783,  0.1874, -0.1438, -0.2047,  0.0762, -0.2322, -0.1453,\n",
       "                        0.0807, -0.0915,  0.1041,  0.1874,  0.1521, -0.1459, -0.2297,  0.0451,\n",
       "                        0.0989,  0.0965, -0.0269,  0.0095,  0.0883, -0.2063,  0.0223, -0.1748,\n",
       "                       -0.1171,  0.1018, -0.1280, -0.1560, -0.1493,  0.1453,  0.1612,  0.0889,\n",
       "                       -0.0907,  0.2436,  0.1993,  0.0342, -0.0782, -0.1426, -0.1111, -0.1219,\n",
       "                       -0.1687,  0.2279, -0.1616, -0.1102,  0.1936, -0.2145, -0.1656, -0.1379,\n",
       "                       -0.1109, -0.0528,  0.1657,  0.0919,  0.1531, -0.1702,  0.0982, -0.1312]],\n",
       "                     device='cuda:0')),\n",
       "             ('linear1.bias', tensor([-0.0530], device='cuda:0'))])"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_path = 'exp/07'\n",
    "os.makedirs(exp_path,exist_ok=True)\n",
    "torch.save(model,os.path.join(exp_path,\"best_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GloveModel(\n",
       "  (embedding): Embedding(400000, 100)\n",
       "  (rnn): GRU(100, 32, num_layers=3, batch_first=True, dropout=0.2, bidirectional=True)\n",
       "  (linear1): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (sig): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = torch.load(os.path.join(exp_path,\"best_model.pt\"))\n",
    "ckpt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
